{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 19.3 gigabytes of available RAM\n",
      "\n",
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import arviz as az\n",
    "\n",
    "import IPython\n",
    "\n",
    "from meridian import constants\n",
    "from meridian.data import load\n",
    "from meridian.data import test_utils\n",
    "from meridian.model import model\n",
    "from meridian.model import spec\n",
    "from meridian.model import prior_distribution\n",
    "from meridian.analysis import optimizer\n",
    "from meridian.analysis import analyzer\n",
    "from meridian.analysis import visualizer\n",
    "from meridian.analysis import summarizer\n",
    "from meridian.analysis import formatter\n",
    "\n",
    "# check if GPU is available\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = 'incrediwear@dataspeaks.io'\n",
    "\n",
    "# BigQuery data\n",
    "project_id = 'ageless-math-320621'\n",
    "dataset_id = 'Models'\n",
    "channel_level_table = 'MMM Aggregated'\n",
    "campaign_level_table = 'MMM Campaigns'\n",
    "platform_level_table = 'MMM Platform'\n",
    "\n",
    "# Media / Control / Target strings to define variables\n",
    "media_str = 'Ads'\n",
    "organic_strs = 'organic'\n",
    "control_str = 'Promotion'\n",
    "web_str = '_web'\n",
    "amazon_str = '_Amazon'\n",
    "all_sales_str = 'Sales_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_project_id: str = \"ageless-math-320621\"\n",
    "bq_client = bigquery.Client(project=gcp_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_bq(\n",
    "    bq_client: bigquery.Client,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_name: str,\n",
    "    client: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Retrieve data from a BigQuery table and return it as a pandas DataFrame.\n",
    "\n",
    "    This function executes a SQL query to select all records from the specified BigQuery table,\n",
    "    filtered by a given username. It converts the result into a pandas DataFrame and the date column.\n",
    "\n",
    "    Parameters:\n",
    "        bq_client (bigquery.Client):\n",
    "            The BigQuery client instance used to execute the query.\n",
    "        project_id (str):\n",
    "            The ID of the Google Cloud project containing the dataset.\n",
    "        dataset_id (str):\n",
    "            The ID of the dataset that contains the target table.\n",
    "        table_name (str):\n",
    "            The name of the table from which to retrieve data.\n",
    "        client (str):\n",
    "            The username used to filter the results.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame:\n",
    "            A pandas DataFrame containing the query results with date columns converted\n",
    "            to datetime and NaN values replaced with zero.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            if there is an error when converting the column date to datetime or filling nan values\n",
    "    \"\"\"\n",
    "    query = f'SELECT * FROM `{project_id}.{dataset_id}.{table_name}` WHERE Username = \"{client}\"'\n",
    "\n",
    "    # Execute the query and convert the result to a pandas DataFrame\n",
    "    df_from_bq = (\n",
    "        bq_client.query(query)\n",
    "        .result()\n",
    "        .to_dataframe(create_bqstorage_client=True, progress_bar_type=\"tqdm\")\n",
    "    )\n",
    "    try:\n",
    "        if \"Date\" in df_from_bq.columns:\n",
    "            df_from_bq[\"Date\"] = pd.to_datetime(df_from_bq[\"Date\"])\n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "            f\"Error converting 'Date' column from dbdatetime to datetime:\\n {e}\\n \",\n",
    "            exc_info=True,\n",
    "        )\n",
    "        raise ValueError(\n",
    "            f\"Error converting 'Date' column from dbdatetime to datetime: \\n {e}\\n \"\n",
    "        ) from e\n",
    "\n",
    "    try:\n",
    "        df_from_bq = df_from_bq.apply(\n",
    "            lambda col: col.replace(np.nan, 0) if col.dtype != \"datetime64[ns]\" else col\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error filling NaN values: \\n {e}\\n \", exc_info=True)\n",
    "        raise ValueError(f\"Error filling NaN values: {e}\") from e\n",
    "\n",
    "    return df_from_bq\n",
    "\n",
    "\n",
    "def get_df_sliced_sorted(df: pd.DataFrame, years: float) -> pd.DataFrame:\n",
    "    \"\"\"Slice and sort a DataFrame based on date values.\n",
    "\n",
    "    This function sorts the provided DataFrame by the 'Date' column in ascending order, converts\n",
    "    the 'Date' column to datetime format, and filters the DataFrame to include only the records\n",
    "    within the specified number of years from the current date.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame):\n",
    "            The input DataFrame containing a 'Date' column to be sliced and sorted.\n",
    "        years (float):\n",
    "            The number of years to look back from the current date.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame:\n",
    "            A new DataFrame containing only the rows with the dates of the specified time window,\n",
    "            sorted by the 'Date' column.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=[\"Date\"], ascending=True)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    time_window_picked = datetime.now() - timedelta(days=years * 365)\n",
    "    today = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    df = df[(df[\"Date\"] > time_window_picked) & (df[\"Date\"] < today)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def cast_weekly_frequency(df_campaigns: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert daily campaign data into a weekly frequency DataFrame by summing numerical features\n",
    "    and retaining the first username for each week.\n",
    "    Parameters:\n",
    "        df_campaigns (pd.DataFrame): A DataFrame containing campaign data with a\n",
    "                                      'Date' column and various numerical columns\n",
    "                                      along with a 'Username' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame indexed by week with the summed values of numerical\n",
    "                       features and the first 'Username' for each week.\n",
    "    \"\"\"\n",
    "    df_campaigns.set_index(\"Date\", inplace=True)\n",
    "    numerical_features = list(df_campaigns.select_dtypes(exclude=\"object\").columns)\n",
    "    df_campaign_weekly = df_campaigns[numerical_features].resample(\"W\").sum()\n",
    "    df_campaign_weekly[\"Username\"] = df_campaigns[\"Username\"].resample(\"W\").first()\n",
    "\n",
    "    return df_campaign_weekly\n",
    "\n",
    "def drop_campaigns(df_campaigns: pd.DataFrame, strings_to_check: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove specified columns from the campaign DataFrame based on provided strings\n",
    "    and drop columns that contain all zero values\n",
    "    Parameters:\n",
    "        df_campaigns (pd.DataFrame): A DataFrame containing campaign data with\n",
    "                                      various columns.\n",
    "        strings_to_check (list): A list of strings to check for in the column names.\n",
    "                                 Any column containing one of these strings will be dropped.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame with specified columns removed and columns\n",
    "                       with all zero values dropped.\n",
    "    \"\"\"\n",
    "    cols_to_drop = [\n",
    "        col\n",
    "        for col in df_campaigns.columns\n",
    "        if any(string in col for string in strings_to_check)\n",
    "    ]\n",
    "    df_campaigns_cleaned = df_campaigns.drop(columns=cols_to_drop)\n",
    "\n",
    "    cols_all_zeros = df_campaigns_cleaned.eq(0).all(axis=0)\n",
    "    df_campaigns_cleaned = df_campaigns_cleaned.drop(\n",
    "        columns=cols_all_zeros[cols_all_zeros].index\n",
    "    )\n",
    "\n",
    "    return df_campaigns_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting db-dtypes==1.3.0\n",
      "  Using cached db_dtypes-1.3.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from db-dtypes==1.3.0) (24.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from db-dtypes==1.3.0) (1.5.3)\n",
      "Collecting pyarrow>=3.0.0 (from db-dtypes==1.3.0)\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from db-dtypes==1.3.0) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from pandas>=0.24.2->db-dtypes==1.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from pandas>=0.24.2->db-dtypes==1.3.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->db-dtypes==1.3.0) (1.17.0)\n",
      "Using cached db_dtypes-1.3.0-py2.py3-none-any.whl (17 kB)\n",
      "Downloading pyarrow-19.0.0-cp310-cp310-macosx_12_0_arm64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, db-dtypes\n",
      "Successfully installed db-dtypes-1.3.0 pyarrow-19.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install db-dtypes==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/fcremer29/focus/meridian_test/demo/env/lib/python3.10/site-packages/google/cloud/bigquery/table.py:2508: UserWarning: A progress bar was requested, but there was an error loading the tqdm library. Please install tqdm to use the progress bar functionality.\n",
      "  record_batch = self.to_arrow(\n"
     ]
    }
   ],
   "source": [
    "df_campaigns_level = get_df_from_bq(bq_client= bq_client, project_id= project_id, dataset_id= dataset_id, table_name= campaign_level_table, client= client)\n",
    "time = df_campaigns_level.Date\n",
    "df_campaigns_level = get_df_sliced_sorted(df=df_campaigns_level, years=2.25)\n",
    "df_campaign_weekly = cast_weekly_frequency(df_campaigns=df_campaigns_level)\n",
    "strings_to_check = ['Sales_Amazon', 'Amazon_', 'Criteo_']\n",
    "df_campaign_weekly_cleaned = drop_campaigns(df_campaigns=df_campaign_weekly, strings_to_check=strings_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_weekly_cleaned.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Facebook_Ads_Tests', 'Facebook_Ads_Retargeting',\n",
       "       'Facebook_Ads_Advantage_Plus', 'TikTok_Ads_Nurturing',\n",
       "       'Google_DSP_Ads_All', 'TikTok_Ads_Prospecting',\n",
       "       'Facebook_Ads_Lead_generation', 'Google_Ads_Video',\n",
       "       'Bing_Ads_Branded_search', 'Bing_Ads_Non_branded_search',\n",
       "       'Bing_Ads_Shopping', 'Google_Ads_Demand_gen', 'Facebook_Ads_Nurturing',\n",
       "       'Google_Ads_Shopping', 'Google_Ads_Non_branded_search',\n",
       "       'Facebook_Ads_Promotions', 'Facebook_Ads_Prospecting',\n",
       "       'Google_Ads_Branded_search', 'Google_Ads_Performance_Max',\n",
       "       'TikTok_Ads_Product_ads', 'Sales_web', 'Promotion', 'Rank',\n",
       "       'Google_Search_Console_Branded_organic',\n",
       "       'Google_Search_Console_Non_branded_organic', 'Social_media_organic',\n",
       "       'Search_organic', 'Email_organic', 'SMS_organic', 'Referral_organic',\n",
       "       'Affiliate_organic', 'Email_campaigns_organic', 'SMS_flows_organic',\n",
       "       'SMS_campaigns_organic', 'Email_flows_organic', 'Username'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_campaign_weekly_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook_Ads_Tests',\n",
       " 'Facebook_Ads_Retargeting',\n",
       " 'Facebook_Ads_Advantage_Plus',\n",
       " 'TikTok_Ads_Nurturing',\n",
       " 'Google_DSP_Ads_All',\n",
       " 'TikTok_Ads_Prospecting',\n",
       " 'Facebook_Ads_Lead_generation',\n",
       " 'Google_Ads_Video',\n",
       " 'Bing_Ads_Branded_search',\n",
       " 'Bing_Ads_Non_branded_search',\n",
       " 'Bing_Ads_Shopping',\n",
       " 'Google_Ads_Demand_gen',\n",
       " 'Facebook_Ads_Nurturing',\n",
       " 'Google_Ads_Shopping',\n",
       " 'Google_Ads_Non_branded_search',\n",
       " 'Facebook_Ads_Promotions',\n",
       " 'Facebook_Ads_Prospecting',\n",
       " 'Google_Ads_Branded_search',\n",
       " 'Google_Ads_Performance_Max',\n",
       " 'TikTok_Ads_Product_ads']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_columns = df_campaign_weekly_cleaned.columns[df_campaign_weekly_cleaned.columns.str.contains('Ads')].tolist()\n",
    "ads_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google_Search_Console_Branded_organic',\n",
       " 'Google_Search_Console_Non_branded_organic',\n",
       " 'Social_media_organic',\n",
       " 'Referral_organic',\n",
       " 'Affiliate_organic',\n",
       " 'Email_campaigns_organic',\n",
       " 'SMS_flows_organic',\n",
       " 'SMS_campaigns_organic',\n",
       " 'Email_flows_organic']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organic_columns = df_campaign_weekly_cleaned.columns[df_campaign_weekly_cleaned.columns.str.contains('organic')].tolist()\n",
    "organic_columns = [col for col in organic_columns if col not in ['Search_organic', 'Email_organic', 'SMS_organic']]\n",
    "organic_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the column names to the variable types. The required variable types are **time, controls, kpi, revenue_per_kpi, media and media_spend**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### controls paramter is required -> GQV is one of the best choices but [Here](https://https://developers.google.com/meridian/docs/advanced-modeling/control-variables) is some theory to guide diverse options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_to_columns = load.CoordToColumns(\n",
    "    time=time,\n",
    "    #geo='geo',\n",
    "    controls=['Promotion', 'Google_Search_Console_Branded_organic','Google_Search_Console_Non_branded_organic' ],\n",
    "    #population='population',\n",
    "    kpi='Sales_web',\n",
    "    #revenue_per_kpi='revenue_per_conversion',\n",
    "    media=ads_columns,\n",
    "    media_spend=ads_columns,\n",
    "    organic_media=organic_columns,\n",
    "    non_media_treatments=['Promotion'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Facebook_Ads_Tests': 'Facebook Tests',\n",
       " 'Facebook_Ads_Retargeting': 'Facebook Retargeting',\n",
       " 'Facebook_Ads_Advantage_Plus': 'Facebook Advantage Plus',\n",
       " 'TikTok_Ads_Nurturing': 'TikTok Nurturing',\n",
       " 'Google_DSP_Ads_All': 'Google DSP All',\n",
       " 'TikTok_Ads_Prospecting': 'TikTok Prospecting',\n",
       " 'Facebook_Ads_Lead_generation': 'Facebook Lead generation',\n",
       " 'Google_Ads_Video': 'Google Video',\n",
       " 'Bing_Ads_Branded_search': 'Bing Branded search',\n",
       " 'Bing_Ads_Non_branded_search': 'Bing Non branded search',\n",
       " 'Bing_Ads_Shopping': 'Bing Shopping',\n",
       " 'Google_Ads_Demand_gen': 'Google Demand gen',\n",
       " 'Facebook_Ads_Nurturing': 'Facebook Nurturing',\n",
       " 'Google_Ads_Shopping': 'Google Shopping',\n",
       " 'Google_Ads_Non_branded_search': 'Google Non branded search',\n",
       " 'Facebook_Ads_Promotions': 'Facebook Promotions',\n",
       " 'Facebook_Ads_Prospecting': 'Facebook Prospecting',\n",
       " 'Google_Ads_Branded_search': 'Google Branded search',\n",
       " 'Google_Ads_Performance_Max': 'Google Performance Max',\n",
       " 'TikTok_Ads_Product_ads': 'TikTok Product ads'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_dict = {ad: ad.replace('_Ads_', ' ').replace('_Ads', '').replace('_', ' ') for ad in ads_columns}\n",
    "ads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_media_to_channel = ads_dict\n",
    "correct_media_spend_to_channel = ads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-11-13', '2022-11-20', '2022-11-27', '2022-12-04',\n",
       "               '2022-12-11', '2022-12-18', '2022-12-25', '2023-01-01',\n",
       "               '2023-01-08', '2023-01-15',\n",
       "               ...\n",
       "               '2024-12-08', '2024-12-15', '2024-12-22', '2024-12-29',\n",
       "               '2025-01-05', '2025-01-12', '2025-01-19', '2025-01-26',\n",
       "               '2025-02-02', '2025-02-09'],\n",
       "              dtype='datetime64[ns]', name='Date', length=118, freq='W-SUN')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_campaign_weekly_cleaned.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime Index error\n",
    "#### we may need to generate GVQ and brainstorm which variables are control variables/confounder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [DatetimeIndex(['2020-03-03', '2020-05-10', '2020-06-29', '2020-07-27',\\n               '2020-09-27', '2021-04-22', '2021-06-21', '2021-11-06',\\n               '2021-11-07', '2021-12-05',\\n               ...\\n               '2024-05-21', '2024-06-01', '2024-06-06', '2024-06-29',\\n               '2024-08-03', '2024-08-11', '2024-08-16', '2024-10-10',\\n               '2025-01-27', '2022-10-13'],\\n              dtype='datetime64[ns]', length=1640, freq=None)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrameDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_campaign_weekly_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkpi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSales_web\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoord_to_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_to_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmedia_to_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorrect_media_to_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmedia_spend_to_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorrect_media_spend_to_channel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:13\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, df, coord_to_columns, kpi_type, media_to_channel, media_spend_to_channel, reach_to_channel, frequency_to_channel, rf_spend_to_channel, organic_reach_to_channel, organic_frequency_to_channel)\u001b[0m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/meridian/data/load.py:808\u001b[0m, in \u001b[0;36mDataFrameDataLoader.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 808\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_normalize_time_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_if_national()\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_names()\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/meridian/data/load.py:827\u001b[0m, in \u001b[0;36mDataFrameDataLoader._validate_and_normalize_time_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validates that time values are in the conventional Meridian format.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03mTime values are expected to be (a) strings formatted in `\"yyyy-mm-dd\"` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03mstrings.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    825\u001b[0m time_column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_to_columns\u001b[38;5;241m.\u001b[39mtime\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_column_name\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    828\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[time_column_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[time_column_name]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    829\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m time: time\u001b[38;5;241m.\u001b[39mstrftime(constants\u001b[38;5;241m.\u001b[39mDATE_FORMAT)\n\u001b[1;32m    830\u001b[0m   )\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m   \u001b[38;5;66;03m# Assume that the `time` column values are strings formatted as dates.\u001b[39;00m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/series.py:1047\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/focus/meridian_test/demo/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [DatetimeIndex(['2020-03-03', '2020-05-10', '2020-06-29', '2020-07-27',\\n               '2020-09-27', '2021-04-22', '2021-06-21', '2021-11-06',\\n               '2021-11-07', '2021-12-05',\\n               ...\\n               '2024-05-21', '2024-06-01', '2024-06-06', '2024-06-29',\\n               '2024-08-03', '2024-08-11', '2024-08-16', '2024-10-10',\\n               '2025-01-27', '2022-10-13'],\\n              dtype='datetime64[ns]', length=1640, freq=None)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "loader = load.DataFrameDataLoader(df=df_campaign_weekly_cleaned, kpi_type= 'Sales_web', coord_to_columns=coord_to_columns, media_to_channel=correct_media_to_channel, media_spend_to_channel=correct_media_spend_to_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = load.CsvDataLoader(\n",
    "    csv_path=\"/Users/fcremer29/focus/meridian_test/meridian/data/simulated_data/csv/geo_all_channels.csv\", #can't use relative path idk why\n",
    "    kpi_type='non_revenue',\n",
    "    coord_to_columns=coord_to_columns,\n",
    "    media_to_channel=correct_media_to_channel,\n",
    "    media_spend_to_channel=correct_media_spend_to_channel,\n",
    ")\n",
    "data = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
